{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_file_path = 'drug_interactions.csv'\n",
    "output_csv_file_path = 'test.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\nightshade\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ICtSP\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your input and output CSV files\n",
    "input_csv_file_path = 'cluster.csv'\n",
    "output_csv_file_path = 'transformed_drug_interactions.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv_file_path)\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    print(\"The input CSV file is empty.\")\n",
    "else:\n",
    "    # Get the last column name\n",
    "    last_column_name = df.columns[-1]\n",
    "\n",
    "    # Initialize the transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # You can change the model to another pre-trained one\n",
    "\n",
    "    # Iterate over each row in the last column, encode the text, and append to the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the text from the last column for the current row\n",
    "        text = str(row[last_column_name])\n",
    "\n",
    "        # Encode the text using the transformer model\n",
    "        embedding = model.encode(text)\n",
    "\n",
    "        # Add each embedding dimension as a new column for the current row\n",
    "        for i, value in enumerate(embedding):\n",
    "            df.at[index, f'{last_column_name}_dim_{i}'] = value\n",
    "\n",
    "    # Save the updated DataFrame with the appended embeddings to a new CSV file\n",
    "    df.to_csv(output_csv_file_path, index=False)\n",
    "\n",
    "    print(f\"Transformed data saved to {output_csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clustered_drug_interactions.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"transformed_drug_interactions.csv\")\n",
    "\n",
    "# Step 1: Extract the transformer output columns\n",
    "transformer_columns = [col for col in df.columns if col.startswith('description_modified_dim_')]\n",
    "transformer_data = df[transformer_columns]\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "transformer_data_scaled = scaler.fit_transform(transformer_data)\n",
    "\n",
    "# Step 3: Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)  # You can change the number of clusters (n_clusters) as needed\n",
    "df['cluster'] = kmeans.fit_predict(transformer_data_scaled)\n",
    "\n",
    "# Save the clustered data to a new CSV file\n",
    "output_file_path = 'clustered_drug_interactions.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep the sentence part, remove the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: first_6_columns.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_first_6_cols = 'first_6_columns.csv'\n",
    "df = pd.read_csv(\"clustered_drug_interactions.csv\")\n",
    "# Select the first 6 columns\n",
    "first_6_columns = df.iloc[:, :6]\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "first_6_columns.to_csv(output_file_first_6_cols, index=False)\n",
    "\n",
    "print(f\"File saved to: {output_file_first_6_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use A and B to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: cluster_description.csv\n"
     ]
    }
   ],
   "source": [
    "cluster_df = pd.read_csv(\"cluster.csv\")\n",
    "cluster_df['description_modified'] = cluster_df.apply(\n",
    "    lambda row: row['description'].replace(row['drug-name'], 'A').replace(row['drug-interact-name'], 'B'), axis=1\n",
    ")\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path_modified = 'cluster_description.csv'\n",
    "cluster_df.to_csv(output_file_path_modified, index=False)\n",
    "\n",
    "print(f\"Modified file saved to: {output_file_path_modified}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'clustered_drug_interactions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Group the data by cluster and get the 'description_modified' for each cluster\n",
    "clustered_descriptions = data.groupby('cluster')['description_modified'].apply(lambda x: list(set(x))).reset_index()\n",
    "\n",
    "# Define the maximum number of columns to display\n",
    "max_cols = 10  # You can adjust this number as needed\n",
    "\n",
    "# Expand the 'description_modified' list into separate columns\n",
    "clustered_descriptions_expanded = clustered_descriptions.copy()\n",
    "clustered_descriptions_expanded[['desc_' + str(i + 1) for i in range(max_cols)]] = pd.DataFrame(\n",
    "    clustered_descriptions['description_modified'].apply(lambda x: x[:max_cols]).to_list(), index=clustered_descriptions.index)\n",
    "\n",
    "# Drop the original 'description_modified' column for better clarity\n",
    "clustered_descriptions_expanded = clustered_descriptions_expanded.drop(columns=['description_modified'])\n",
    "\n",
    "# Save the expanded dataframe to a CSV file\n",
    "output_file_path = 'clustered_descriptions_expanded.csv'  # Replace with your desired output file path\n",
    "clustered_descriptions_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"The CSV file has been saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightshade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
